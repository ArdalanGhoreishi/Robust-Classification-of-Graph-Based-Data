{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "usps4and9_test.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLFoUwOqrHz9"
      },
      "source": [
        "!pip install extra_keras_datasets -q"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iifuj4Xh2vxT"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "from numpy.linalg import matrix_power\n",
        "import random\n",
        "import math as m\n",
        "import scipy"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXvbkGdX5zep"
      },
      "source": [
        "def RobustGC(W, y_train_prime, eta):\n",
        "  D = np.zeros ((len(W),len(W)))\n",
        "  for i in range (len(W)):\n",
        "    D[i][i]= np.sum(W[i] , axis=0)\n",
        "\n",
        "  D_inv = np.sqrt(matrix_power(D,-1))\n",
        "  S = D_inv @ W @ D_inv\n",
        "  LN = np.eye(len(S)) - S\n",
        "  V0 = np.zeros(len(D))\n",
        "\n",
        "  for i in range (len (D)):\n",
        "    V0[i]= np.sqrt(D[i][i])\n",
        "\n",
        "  V0_norm = np.linalg.norm(V0, 2)\n",
        "  V0= V0/V0_norm\n",
        "  v=np.linalg.eigvals(LN)\n",
        "  v=sorted(v)\n",
        "  lambda_1 = v[1]\n",
        "  gamma_t= eta*lambda_1\n",
        "  # print(gamma_t)\n",
        "  \n",
        "  f = np.linalg.inv((LN/gamma_t)-np.eye(len(LN)))@(y_train_prime - (np.dot(V0,np.dot(V0.transpose(), y_train_prime))))\n",
        "  pred= np.sign(f)\n",
        "  pred = np.squeeze(np.asarray(pred))\n",
        "  # print (pred)\n",
        "\n",
        "  return pred, gamma_t"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxQm5M8hSNC5"
      },
      "source": [
        "def PF_RobustGC(W, y_train_prime):\n",
        "  D = np.zeros ((len(W),len(W)))\n",
        "  for i in range (len(W)):\n",
        "    D[i][i]= np.sum(W[i] , axis=0)\n",
        "\n",
        "  D_inv = np.sqrt(matrix_power(D,-1))\n",
        "  S = D_inv @ W @ D_inv\n",
        "  LN = np.eye(len(S)) - S\n",
        "  V0 = np.zeros(len(D))\n",
        "\n",
        "  for i in range (len (D)):\n",
        "    V0[i]= np.sqrt(D[i][i])\n",
        "\n",
        "  V0_norm = np.linalg.norm(V0, 2)\n",
        "  V0= V0/V0_norm\n",
        "  v=np.linalg.eigvals(LN)\n",
        "  v=sorted(v)\n",
        "  lambda_1 = v[1]\n",
        "  gamma_t= 0.9*lambda_1\n",
        "  # print(gamma_t)\n",
        "  \n",
        "  f = np.linalg.inv((LN/gamma_t)-np.eye(len(LN)))@(y_train_prime - (np.dot(V0,np.dot(V0.transpose(), y_train_prime))))\n",
        "  pred= np.sign(f)\n",
        "  pred = np.squeeze(np.asarray(pred))\n",
        "  # print (pred)\n",
        "\n",
        "  return pred, gamma_t"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "El5brn-QUc17"
      },
      "source": [
        "def accuracy (y_pred , y_orig):\n",
        "  count=0\n",
        "  for i in range (len(y_pred)):\n",
        "    if y_pred[i]==y_orig[i]:\n",
        "      count+=1\n",
        "  result = count/len(y_pred) * 100\n",
        "  return result"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gn6FbkwKXCpN",
        "outputId": "7b68b3b2-328a-402b-8cbc-46098ccc2c63"
      },
      "source": [
        "from extra_keras_datasets import usps\n",
        "(X_train, y_train), (X_test,y_test) = usps.load_data()\n",
        "filter_nine = np.where(y_train == 9)\n",
        "filter_four = np.where(y_train == 4)\n",
        "X_train_9 = X_train[filter_nine]\n",
        "X_train_4 = X_train[filter_four]\n",
        "X_train_9_125 = X_train_9[0:125]\n",
        "X_train_4_125 = X_train_4[0:125]\n",
        "y_train = [1]*125 + [-1]*125\n",
        "X_train = np.append(X_train_4_125, X_train_9_125, axis=0)\n",
        "from sklearn.utils import shuffle\n",
        "X_train, y_train = shuffle(X_train, y_train)\n",
        "X_train = X_train.reshape(-1, 16*16)\n",
        "def GaussianKernel(v1, v2, sigma):\n",
        "  #sigma = 0.47\n",
        "  dist = scipy.spatial.distance.braycurtis(v1, v2)\n",
        "  return scipy.exp(-np.sum(dist**2) / (2.*sigma**2))\n",
        "\n",
        "W = np.zeros((len(X_train), len(X_train)))\n",
        "#W=polynomial_kernel(X_train, gamma=26.5 ,degree=3 )\n",
        "for i in range(len(X_train)):\n",
        "  for j in range(len(X_train)):\n",
        "    W[i][j] = GaussianKernel(X_train[i], X_train[j], sigma=0.47)\n",
        "acc = np.zeros (20)\n",
        "for i in range (20):\n",
        "  y_train_prime = y_train.copy()\n",
        "  ra = random.sample(range(0, 250), 125)\n",
        "  for j in ra:\n",
        "    y_train_prime[j]=0  \n",
        "  pred , gamma_t = RobustGC (W, y_train_prime , 0.85)\n",
        "  acc[i] = accuracy (pred , y_train)\n",
        "print (np.mean(acc))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:root:Loading dataset = usps\n",
            "WARNING:root:Please cite the following paper when using or referencing this Extra Keras Dataset:\n",
            "WARNING:root:Hull, J. J. (1994). A database for handwritten text recognition research. IEEE Transactions on pattern analysis and machine intelligence, 16(5), 550-554.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:17: DeprecationWarning: scipy.exp is deprecated and will be removed in SciPy 2.0.0, use numpy.exp instead\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "93.97999999999999\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rhAY3leSZdvK",
        "outputId": "6f66aebc-a091-4d10-ae15-1a600c96eb78"
      },
      "source": [
        "from extra_keras_datasets import usps\n",
        "(X_train, y_train), (X_test,y_test) = usps.load_data()\n",
        "filter_nine = np.where(y_train == 9)\n",
        "filter_four = np.where(y_train == 4)\n",
        "X_train_9 = X_train[filter_nine]\n",
        "X_train_4 = X_train[filter_four]\n",
        "X_train_9_125 = X_train_9[0:125]\n",
        "X_train_4_125 = X_train_4[0:125]\n",
        "y_train = [1]*125 + [-1]*125\n",
        "X_train = np.append(X_train_4_125, X_train_9_125, axis=0)\n",
        "from sklearn.utils import shuffle\n",
        "X_train, y_train = shuffle(X_train, y_train)\n",
        "X_train = X_train.reshape(-1, 16*16)\n",
        "def GaussianKernel(v1, v2, sigma):\n",
        "  #sigma = 0.47\n",
        "  dist = scipy.spatial.distance.braycurtis(v1, v2)\n",
        "  return scipy.exp(-np.sum(dist**2) / (2.*sigma**2))\n",
        "\n",
        "W = np.zeros((len(X_train), len(X_train)))\n",
        "#W=polynomial_kernel(X_train, gamma=26.5 ,degree=3 )\n",
        "for i in range(len(X_train)):\n",
        "  for j in range(len(X_train)):\n",
        "    W[i][j] = GaussianKernel(X_train[i], X_train[j], sigma=0.47)\n",
        "acc = np.zeros (20)\n",
        "for i in range (20):\n",
        "  y_train_prime = y_train.copy()\n",
        "  ra = random.sample(range(0, 250), 125)\n",
        "  for j in ra:\n",
        "    y_train_prime[j]=0  \n",
        "  pred , gamma_t = PF_RobustGC (W, y_train_prime)\n",
        "  acc[i] = accuracy (pred , y_train)\n",
        "print (np.mean(acc))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:root:Loading dataset = usps\n",
            "WARNING:root:Please cite the following paper when using or referencing this Extra Keras Dataset:\n",
            "WARNING:root:Hull, J. J. (1994). A database for handwritten text recognition research. IEEE Transactions on pattern analysis and machine intelligence, 16(5), 550-554.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:17: DeprecationWarning: scipy.exp is deprecated and will be removed in SciPy 2.0.0, use numpy.exp instead\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "94.03999999999999\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}